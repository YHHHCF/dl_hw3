{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'phoneme_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a1bad78ff5a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mphoneme_list\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'phoneme_list'"
     ]
    }
   ],
   "source": [
    "import phoneme_list as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "import Levenshtein as L\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "n_stat = pl.N_STATES\n",
    "n_phon = pl.N_PHONEMES\n",
    "p_list = pl.PHONEME_LIST\n",
    "p_map = pl.PHONEME_MAP\n",
    "\n",
    "train_data_path = './../data/wsj0_train.npy'\n",
    "train_label_path = './../data/wsj0_train_merged_labels.npy'\n",
    "\n",
    "val_data_path = './../data/wsj0_dev.npy'\n",
    "val_label_path = './../data/wsj0_dev_merged_labels.npy'\n",
    "\n",
    "test_path = './../data/transformed_test_data.npy'\n",
    "\n",
    "train_data = np.load(train_data_path, encoding='bytes')\n",
    "train_label = np.load(train_label_path)\n",
    "\n",
    "val_data = np.load(val_data_path, encoding='bytes')\n",
    "val_label = np.load(val_label_path)\n",
    "\n",
    "\n",
    "# phonome dataset, init dataset with data and label\n",
    "class PhonDataset(Dataset):\n",
    "    def __init__(self, phon_list, labels):\n",
    "        self.data = [torch.tensor(phon) for phon in phon_list]\n",
    "        self.labels = [torch.tensor(label) for label in labels]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        data = self.data[i]\n",
    "        label = self.labels[i]\n",
    "        data = data.type(torch.float32)\n",
    "        return data.to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "# collate_phon return your data sorted by length\n",
    "def collate_phon(phon_list):\n",
    "    inputs, targets = zip(*phon_list)\n",
    "    lens = [len(phon) for phon in inputs]\n",
    "    seq_order = sorted(range(len(lens)), key=lens.__getitem__, reverse=True)\n",
    "    inputs = [inputs[i] for i in seq_order]\n",
    "    targets = [targets[i] for i in seq_order]\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "def print_model(model):\n",
    "    params = model.state_dict()\n",
    "    keys = params.keys()\n",
    "    for key in keys:\n",
    "        print(key + \": \")\n",
    "        print(torch.max(params[key]))\n",
    "    return\n",
    "\n",
    "\n",
    "# phonome dataloader\n",
    "# Model that takes packed sequences in training\n",
    "class PackedPhonModel(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, nlayers):\n",
    "        super(PackedPhonModel, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers = nlayers\n",
    "        self.rnn = nn.LSTM(input_size=in_size, hidden_size=hidden_size, num_layers=nlayers, bidirectional=True)\n",
    "        self.scoring1 = nn.Linear(2 * hidden_size, 1024)\n",
    "        self.scoring2 = nn.Linear(1024, out_size)\n",
    "        self.lsm = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, phon_list):  # list\n",
    "        # pack and split the length sorted input into small pieces\n",
    "        packed_input = rnn.pack_sequence(phon_list)  # packed version\n",
    "\n",
    "        hidden = None\n",
    "        output_packed, hidden = self.rnn(packed_input, hidden)\n",
    "\n",
    "        # get the output with dim 0 corresponding to packed_input\n",
    "        output_padded, _ = rnn.pad_packed_sequence(output_packed)  # unpacked output (padded)\n",
    "        scores_flatten = self.scoring1(output_padded)  # concatenated logits\n",
    "        scores_flatten = self.scoring2(output_padded)\n",
    "        scores_flatten = self.lsm(scores_flatten)\n",
    "\n",
    "        return scores_flatten  # return concatenated logits\n",
    "    \n",
    "    \n",
    "def save_ckpt(model, optimizer, val_loss, idx):\n",
    "    id_name = 'id_' + str(idx)\n",
    "    path = './../result/' + id_name\n",
    "\n",
    "    torch.save({\n",
    "        'exp_id': idx,\n",
    "        'val_loss': val_loss,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, path)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def load_ckpt(path):\n",
    "    new_model = PackedPhonModel(40, 512, 47, 4)\n",
    "    pretrained_ckpt = torch.load(path)\n",
    "    new_model.load_state_dict(pretrained_ckpt['model_state_dict'])\n",
    "    \n",
    "    new_optimizer = torch.optim.Adam(new_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "    new_optimizer.load_state_dict(pretrained_ckpt['optimizer_state_dict'])\n",
    "    return new_model, new_optimizer\n",
    "\n",
    "\n",
    "def train(epochs, train_loader, val_loader, model, writer):\n",
    "    model.train()\n",
    "    idx = 0\n",
    "    for e in range(epochs):\n",
    "        print(\"begin epoch: \", e)\n",
    "        for inputs, targets in train_loader:\n",
    "            idx += 1\n",
    "            # inputs is a list of 64 frames, each frame is K * 40, with K varies\n",
    "            # targets is a list of 64 target vectors, each containing T values, T varies\n",
    "            in_lens = [len(phon) for phon in inputs]\n",
    "            tar_lens = [len(tar) for tar in targets]\n",
    "\n",
    "            in_lens = torch.tensor(in_lens)\n",
    "            tar_lens = torch.tensor(tar_lens)\n",
    "\n",
    "            packed_targets = torch.cat(targets, dim=0)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, packed_targets, in_lens, tar_lens)\n",
    "            \n",
    "            writer.add_scalar('train/loss', loss.item(), idx)\n",
    "\n",
    "            # perform backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        val_loss = val(model, val_loader, writer, e)\n",
    "        model.train()\n",
    "        save_ckpt(model, optimizer, val_loss, e)\n",
    "            \n",
    "            \n",
    "# validation\n",
    "def val(model, val_loader, writer, ep):\n",
    "    model.eval()\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        cnt += 1\n",
    "        avg_loss = 0\n",
    "        for inputs, targets in val_loader:\n",
    "            in_lens = [len(phon) for phon in inputs]\n",
    "            tar_lens = [len(tar) for tar in targets]\n",
    "\n",
    "            in_lens = torch.tensor(in_lens)\n",
    "            tar_lens = torch.tensor(tar_lens)\n",
    "\n",
    "            packed_targets = torch.cat(targets, dim=0)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, packed_targets, in_lens, tar_lens)\n",
    "            avg_loss += loss.item()\n",
    "        avg_loss /= cnt\n",
    "        writer.add_scalar('val/loss', avg_loss.item(), ep)\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PackedPhonModel(40, 512, 47, 4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_dataset = PhonDataset(train_data, train_label)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, collate_fn=collate_phon)\n",
    "\n",
    "val_dataset = PhonDataset(val_data, val_label)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=64, collate_fn=collate_phon)\n",
    "\n",
    "criterion = nn.CTCLoss(blank=46)\n",
    "criterion = criterion.to(DEVICE)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "epochs = 5\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin epoch:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bdd21d9a91f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-888d0716cd27>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, train_loader, val_loader, model, writer)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs, train_loader, val_loader, model, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "path = './../result/id_0'\n",
    "model = load_ckpt(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '+', '~', '!', '-', '@', 'a', 'A', 'h', 'o', 'w', 'y', 'b', 'c', 'd', 'D', 'e', 'r', 'E', 'f', 'g', 'H', 'i', 'I', 'j', 'k', 'l', 'm', 'n', 'G', 'O', 'Y', 'p', 'R', 's', 'S', '.', 't', 'T', 'u', 'U', 'v', 'W', '?', 'z', 'Z', '%']\n"
     ]
    }
   ],
   "source": [
    "# tokens is the list of vocab index predicted\n",
    "# vocab is the vocabulary map\n",
    "def convert_to_string(tokens, vocab, seq_len):\n",
    "    print(seq_len)\n",
    "    return ''.join([vocab[x] for x in tokens[0:seq_len]])\n",
    "\n",
    "# the list\n",
    "p_map = pl.PHONEME_MAP\n",
    "p_map.append('%')\n",
    "print(p_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a04a51818e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_loader2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_phon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassification_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "val_loader2 = DataLoader(val_dataset, shuffle=False, batch_size=1, collate_fn=collate_phon)\n",
    "\n",
    "classification_result = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader2:\n",
    "        output = model(inputs)\n",
    "        sp = output.shape\n",
    "        output = output.reshape((sp[0], sp[2]))\n",
    "        output = output.cpu().numpy()\n",
    "        print(output.shape)\n",
    "        \n",
    "        probs_seq = torch.FloatTensor([output])\n",
    "        \n",
    "        print(probs_seq[0].shape)\n",
    "        \n",
    "        decoder = CTCBeamDecoder(p_map, beam_width=100, blank_id=p_map.index('%'))\n",
    "        output, scores, timesteps, out_seq_len = decoder.decode(probs_seq)\n",
    "#         print(out_seq_len)\n",
    "#         print(beam_result.shape)\n",
    "        for i in range(output.size(0)):\n",
    "            pred = \"\".join(p_map[o] for o in output[i, 0, :out_seq_len[i, 0]])\n",
    "        print(pred)\n",
    "#         pred_str = convert_to_string(beam_result[0][0], p_map, out_seq_len[0][0])\n",
    "        \n",
    "\n",
    "#         print(out_seq_len[0][0])\n",
    "#         print(pred_str)\n",
    "#         print(len(pred_str))\n",
    "#         print(targets)\n",
    "        \n",
    "#         true = ''.join([vocab[x] for x in tokens[0:seq_len]])\n",
    "#         true = convert_to_string(targets, p_map, len(targets))\n",
    "#         true = convert_to_string(targets, p_map, 10)\n",
    "\n",
    "#         L.distance(pred_str, true)\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542, 47)\n",
      "(681, 47)\n",
      "(646, 47)\n",
      "(600, 47)\n",
      "(578, 47)\n",
      "(1325, 47)\n",
      "(1086, 47)\n",
      "(1038, 47)\n",
      "(877, 47)\n",
      "(819, 47)\n",
      "(520, 47)\n",
      "(739, 47)\n",
      "(741, 47)\n",
      "(923, 47)\n",
      "(719, 47)\n",
      "(476, 47)\n",
      "(765, 47)\n",
      "(429, 47)\n",
      "(566, 47)\n",
      "(486, 47)\n",
      "(484, 47)\n",
      "(712, 47)\n",
      "(806, 47)\n",
      "(799, 47)\n",
      "(790, 47)\n",
      "(792, 47)\n",
      "(522, 47)\n",
      "(550, 47)\n",
      "(594, 47)\n",
      "(563, 47)\n",
      "(1027, 47)\n",
      "(664, 47)\n",
      "(540, 47)\n",
      "(948, 47)\n",
      "(1202, 47)\n",
      "(963, 47)\n",
      "(269, 47)\n",
      "(840, 47)\n",
      "(486, 47)\n",
      "(771, 47)\n",
      "(493, 47)\n",
      "(931, 47)\n",
      "(462, 47)\n",
      "(412, 47)\n",
      "(1419, 47)\n",
      "(708, 47)\n",
      "(683, 47)\n",
      "(904, 47)\n",
      "(169, 47)\n",
      "(432, 47)\n",
      "(582, 47)\n",
      "(465, 47)\n",
      "(1242, 47)\n",
      "(820, 47)\n",
      "(340, 47)\n",
      "(838, 47)\n",
      "(1418, 47)\n",
      "(1114, 47)\n",
      "(620, 47)\n",
      "(665, 47)\n",
      "(756, 47)\n",
      "(529, 47)\n",
      "(344, 47)\n",
      "(622, 47)\n",
      "(410, 47)\n",
      "(1102, 47)\n",
      "(565, 47)\n",
      "(646, 47)\n",
      "(732, 47)\n",
      "(623, 47)\n",
      "(704, 47)\n",
      "(461, 47)\n",
      "(643, 47)\n",
      "(619, 47)\n",
      "(585, 47)\n",
      "(895, 47)\n",
      "(1055, 47)\n",
      "(533, 47)\n",
      "(503, 47)\n",
      "(219, 47)\n",
      "(1093, 47)\n",
      "(674, 47)\n",
      "(1187, 47)\n",
      "(554, 47)\n",
      "(532, 47)\n",
      "(183, 47)\n",
      "(259, 47)\n",
      "(935, 47)\n",
      "(813, 47)\n",
      "(958, 47)\n",
      "(244, 47)\n",
      "(803, 47)\n",
      "(379, 47)\n",
      "(660, 47)\n",
      "(644, 47)\n",
      "(641, 47)\n",
      "(920, 47)\n",
      "(300, 47)\n",
      "(637, 47)\n",
      "(366, 47)\n",
      "(915, 47)\n",
      "(957, 47)\n",
      "(786, 47)\n",
      "(681, 47)\n",
      "(1284, 47)\n",
      "(1043, 47)\n",
      "(579, 47)\n",
      "(954, 47)\n",
      "(242, 47)\n",
      "(990, 47)\n",
      "(732, 47)\n",
      "(782, 47)\n",
      "(452, 47)\n",
      "(633, 47)\n",
      "(595, 47)\n",
      "(1196, 47)\n",
      "(571, 47)\n",
      "(449, 47)\n",
      "(475, 47)\n",
      "(545, 47)\n",
      "(628, 47)\n",
      "(454, 47)\n",
      "(757, 47)\n",
      "(392, 47)\n",
      "(845, 47)\n",
      "(773, 47)\n",
      "(815, 47)\n",
      "(717, 47)\n",
      "(1045, 47)\n",
      "(771, 47)\n",
      "(778, 47)\n",
      "(454, 47)\n",
      "(501, 47)\n",
      "(842, 47)\n",
      "(558, 47)\n",
      "(476, 47)\n",
      "(302, 47)\n",
      "(789, 47)\n",
      "(547, 47)\n",
      "(686, 47)\n",
      "(535, 47)\n",
      "(717, 47)\n",
      "(391, 47)\n",
      "(871, 47)\n",
      "(1165, 47)\n",
      "(1142, 47)\n",
      "(1185, 47)\n",
      "(617, 47)\n",
      "(737, 47)\n",
      "(545, 47)\n",
      "(1340, 47)\n",
      "(1021, 47)\n",
      "(643, 47)\n",
      "(965, 47)\n",
      "(993, 47)\n",
      "(1023, 47)\n",
      "(868, 47)\n",
      "(773, 47)\n",
      "(357, 47)\n",
      "(462, 47)\n",
      "(999, 47)\n",
      "(529, 47)\n",
      "(627, 47)\n",
      "(578, 47)\n",
      "(900, 47)\n",
      "(719, 47)\n",
      "(529, 47)\n",
      "(459, 47)\n",
      "(751, 47)\n",
      "(1142, 47)\n",
      "(416, 47)\n",
      "(392, 47)\n",
      "(347, 47)\n",
      "(479, 47)\n",
      "(1046, 47)\n",
      "(193, 47)\n",
      "(646, 47)\n",
      "(829, 47)\n",
      "(363, 47)\n",
      "(957, 47)\n",
      "(313, 47)\n",
      "(524, 47)\n",
      "(1214, 47)\n",
      "(795, 47)\n",
      "(392, 47)\n",
      "(982, 47)\n",
      "(1114, 47)\n",
      "(1302, 47)\n",
      "(667, 47)\n",
      "(980, 47)\n",
      "(843, 47)\n",
      "(1033, 47)\n",
      "(724, 47)\n",
      "(800, 47)\n",
      "(655, 47)\n",
      "(428, 47)\n",
      "(1085, 47)\n",
      "(786, 47)\n",
      "(698, 47)\n",
      "(1003, 47)\n",
      "(693, 47)\n",
      "(416, 47)\n",
      "(804, 47)\n",
      "(1252, 47)\n",
      "(898, 47)\n",
      "(436, 47)\n",
      "(528, 47)\n",
      "(806, 47)\n",
      "(418, 47)\n",
      "(1292, 47)\n",
      "(513, 47)\n",
      "(997, 47)\n",
      "(491, 47)\n",
      "(564, 47)\n",
      "(801, 47)\n",
      "(764, 47)\n",
      "(340, 47)\n",
      "(488, 47)\n",
      "(485, 47)\n",
      "(931, 47)\n",
      "(552, 47)\n",
      "(600, 47)\n",
      "(1309, 47)\n",
      "(1018, 47)\n",
      "(1477, 47)\n",
      "(579, 47)\n",
      "(497, 47)\n",
      "(556, 47)\n",
      "(391, 47)\n",
      "(865, 47)\n",
      "(1063, 47)\n",
      "(878, 47)\n",
      "(749, 47)\n",
      "(897, 47)\n",
      "(1049, 47)\n",
      "(540, 47)\n",
      "(500, 47)\n",
      "(797, 47)\n",
      "(467, 47)\n",
      "(806, 47)\n",
      "(792, 47)\n",
      "(1112, 47)\n",
      "(770, 47)\n",
      "(277, 47)\n",
      "(332, 47)\n",
      "(1153, 47)\n",
      "(938, 47)\n",
      "(1141, 47)\n",
      "(923, 47)\n",
      "(730, 47)\n",
      "(543, 47)\n",
      "(935, 47)\n",
      "(851, 47)\n",
      "(436, 47)\n",
      "(619, 47)\n",
      "(983, 47)\n",
      "(985, 47)\n",
      "(668, 47)\n",
      "(1251, 47)\n",
      "(600, 47)\n",
      "(740, 47)\n",
      "(609, 47)\n",
      "(285, 47)\n",
      "(817, 47)\n",
      "(723, 47)\n",
      "(460, 47)\n",
      "(373, 47)\n",
      "(273, 47)\n",
      "(1107, 47)\n",
      "(697, 47)\n",
      "(971, 47)\n",
      "(509, 47)\n",
      "(415, 47)\n",
      "(695, 47)\n",
      "(640, 47)\n",
      "(922, 47)\n",
      "(527, 47)\n",
      "(443, 47)\n",
      "(403, 47)\n",
      "(355, 47)\n",
      "(652, 47)\n",
      "(788, 47)\n",
      "(624, 47)\n",
      "(972, 47)\n",
      "(758, 47)\n",
      "(490, 47)\n",
      "(670, 47)\n",
      "(286, 47)\n",
      "(462, 47)\n",
      "(716, 47)\n",
      "(1007, 47)\n",
      "(766, 47)\n",
      "(989, 47)\n",
      "(212, 47)\n",
      "(1141, 47)\n",
      "(489, 47)\n",
      "(909, 47)\n",
      "(588, 47)\n",
      "(667, 47)\n",
      "(666, 47)\n",
      "(653, 47)\n",
      "(1425, 47)\n",
      "(546, 47)\n",
      "(1002, 47)\n",
      "(666, 47)\n",
      "(881, 47)\n",
      "(259, 47)\n",
      "(890, 47)\n",
      "(841, 47)\n",
      "(435, 47)\n",
      "(686, 47)\n",
      "(567, 47)\n",
      "(909, 47)\n",
      "(1205, 47)\n",
      "(1061, 47)\n",
      "(514, 47)\n",
      "(499, 47)\n",
      "(473, 47)\n",
      "(796, 47)\n",
      "(392, 47)\n",
      "(766, 47)\n",
      "(689, 47)\n",
      "(696, 47)\n",
      "(716, 47)\n",
      "(799, 47)\n",
      "(909, 47)\n",
      "(519, 47)\n",
      "(528, 47)\n",
      "(500, 47)\n",
      "(488, 47)\n",
      "(1268, 47)\n",
      "(874, 47)\n",
      "(587, 47)\n",
      "(407, 47)\n",
      "(446, 47)\n",
      "(944, 47)\n",
      "(1063, 47)\n",
      "(567, 47)\n",
      "(699, 47)\n",
      "(531, 47)\n",
      "(1039, 47)\n",
      "(542, 47)\n",
      "(809, 47)\n",
      "(881, 47)\n",
      "(742, 47)\n",
      "(736, 47)\n",
      "(696, 47)\n",
      "(729, 47)\n",
      "(940, 47)\n",
      "(387, 47)\n",
      "(785, 47)\n",
      "(597, 47)\n",
      "(857, 47)\n",
      "(1022, 47)\n",
      "(1260, 47)\n",
      "(1089, 47)\n",
      "(1104, 47)\n",
      "(778, 47)\n",
      "(1005, 47)\n",
      "(1418, 47)\n",
      "(802, 47)\n",
      "(1219, 47)\n",
      "(672, 47)\n",
      "(950, 47)\n",
      "(359, 47)\n",
      "(1046, 47)\n",
      "(345, 47)\n",
      "(592, 47)\n",
      "(652, 47)\n",
      "(977, 47)\n",
      "(683, 47)\n",
      "(626, 47)\n",
      "(411, 47)\n",
      "(340, 47)\n",
      "(770, 47)\n",
      "(1596, 47)\n",
      "(697, 47)\n",
      "(788, 47)\n",
      "(525, 47)\n",
      "(654, 47)\n",
      "(760, 47)\n",
      "(557, 47)\n",
      "(343, 47)\n",
      "(615, 47)\n",
      "(511, 47)\n",
      "(797, 47)\n",
      "(553, 47)\n",
      "(1004, 47)\n",
      "(561, 47)\n",
      "(551, 47)\n",
      "(690, 47)\n",
      "(1029, 47)\n",
      "(605, 47)\n",
      "(752, 47)\n",
      "(586, 47)\n",
      "(361, 47)\n",
      "(1020, 47)\n",
      "(290, 47)\n",
      "(638, 47)\n",
      "(283, 47)\n",
      "(608, 47)\n",
      "(901, 47)\n",
      "(375, 47)\n",
      "(963, 47)\n",
      "(755, 47)\n",
      "(1017, 47)\n",
      "(642, 47)\n",
      "(588, 47)\n",
      "(782, 47)\n",
      "(700, 47)\n",
      "(697, 47)\n",
      "(737, 47)\n",
      "(394, 47)\n",
      "(899, 47)\n",
      "(852, 47)\n",
      "(758, 47)\n",
      "(816, 47)\n",
      "(367, 47)\n",
      "(534, 47)\n",
      "(1316, 47)\n",
      "(611, 47)\n",
      "(795, 47)\n",
      "(877, 47)\n",
      "(589, 47)\n",
      "(1034, 47)\n",
      "(707, 47)\n",
      "(559, 47)\n",
      "(1481, 47)\n",
      "(829, 47)\n",
      "(988, 47)\n",
      "(634, 47)\n",
      "(1114, 47)\n",
      "(530, 47)\n",
      "(749, 47)\n",
      "(1417, 47)\n",
      "(452, 47)\n",
      "(897, 47)\n",
      "(734, 47)\n",
      "(479, 47)\n",
      "(703, 47)\n",
      "(626, 47)\n",
      "(884, 47)\n",
      "(986, 47)\n",
      "(680, 47)\n",
      "(940, 47)\n",
      "(548, 47)\n",
      "(1049, 47)\n",
      "(425, 47)\n",
      "(1600, 47)\n",
      "(1111, 47)\n",
      "(346, 47)\n",
      "(650, 47)\n",
      "(624, 47)\n",
      "(987, 47)\n",
      "(708, 47)\n",
      "(266, 47)\n",
      "(359, 47)\n",
      "(669, 47)\n",
      "(560, 47)\n",
      "(835, 47)\n",
      "(767, 47)\n",
      "(832, 47)\n",
      "(374, 47)\n",
      "(1138, 47)\n",
      "(983, 47)\n",
      "(819, 47)\n",
      "(1180, 47)\n",
      "(658, 47)\n",
      "(487, 47)\n",
      "(298, 47)\n",
      "(350, 47)\n",
      "(639, 47)\n",
      "(796, 47)\n",
      "(875, 47)\n",
      "(602, 47)\n",
      "(930, 47)\n",
      "(593, 47)\n",
      "(944, 47)\n",
      "(855, 47)\n",
      "(1123, 47)\n",
      "(874, 47)\n",
      "(986, 47)\n",
      "(974, 47)\n",
      "(426, 47)\n",
      "(494, 47)\n",
      "(529, 47)\n",
      "(677, 47)\n",
      "(900, 47)\n",
      "(1233, 47)\n",
      "(533, 47)\n",
      "(390, 47)\n",
      "(895, 47)\n",
      "(712, 47)\n",
      "(944, 47)\n",
      "(328, 47)\n",
      "(909, 47)\n",
      "(736, 47)\n",
      "(603, 47)\n",
      "(369, 47)\n",
      "(430, 47)\n",
      "(659, 47)\n",
      "(536, 47)\n",
      "(1045, 47)\n",
      "(663, 47)\n",
      "(906, 47)\n",
      "(497, 47)\n",
      "(1151, 47)\n",
      "(627, 47)\n",
      "(890, 47)\n",
      "(660, 47)\n",
      "(630, 47)\n",
      "(233, 47)\n",
      "(782, 47)\n",
      "(917, 47)\n",
      "(830, 47)\n",
      "(688, 47)\n",
      "(320, 47)\n",
      "(923, 47)\n",
      "(1159, 47)\n",
      "(889, 47)\n",
      "(641, 47)\n",
      "(1061, 47)\n",
      "(502, 47)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_data = np.load(test_path, encoding='bytes')\n",
    "test_len = len(test_data)\n",
    "test_label = val_label[:test_len]\n",
    "\n",
    "test_dataset = PhonDataset(test_data, test_label)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=1, collate_fn=collate_phon)\n",
    "\n",
    "outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        output = model(inputs)\n",
    "        sp = output.shape\n",
    "        output = output.reshape((sp[0], sp[2]))\n",
    "        output = output.cpu().numpy()\n",
    "        outputs.append(output)\n",
    "        print(output.shape)\n",
    "\n",
    "np.save(\"outputs_2.npy\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542, 40)\n",
      "(681, 40)\n",
      "(646, 40)\n",
      "(600, 40)\n",
      "(578, 40)\n",
      "(1325, 40)\n",
      "(1086, 40)\n",
      "(1038, 40)\n",
      "(877, 40)\n",
      "(819, 40)\n",
      "(520, 40)\n",
      "(739, 40)\n",
      "(741, 40)\n",
      "(923, 40)\n",
      "(719, 40)\n",
      "(476, 40)\n",
      "(765, 40)\n",
      "(429, 40)\n",
      "(566, 40)\n",
      "(486, 40)\n",
      "(484, 40)\n",
      "(712, 40)\n",
      "(806, 40)\n",
      "(799, 40)\n",
      "(790, 40)\n",
      "(792, 40)\n",
      "(522, 40)\n",
      "(550, 40)\n",
      "(594, 40)\n",
      "(563, 40)\n",
      "(1027, 40)\n",
      "(664, 40)\n",
      "(540, 40)\n",
      "(948, 40)\n",
      "(1202, 40)\n",
      "(963, 40)\n",
      "(269, 40)\n",
      "(840, 40)\n",
      "(486, 40)\n",
      "(771, 40)\n",
      "(493, 40)\n",
      "(931, 40)\n",
      "(462, 40)\n",
      "(412, 40)\n",
      "(1419, 40)\n",
      "(708, 40)\n",
      "(683, 40)\n",
      "(904, 40)\n",
      "(169, 40)\n",
      "(432, 40)\n",
      "(582, 40)\n",
      "(465, 40)\n",
      "(1242, 40)\n",
      "(820, 40)\n",
      "(340, 40)\n",
      "(838, 40)\n",
      "(1418, 40)\n",
      "(1114, 40)\n",
      "(620, 40)\n",
      "(665, 40)\n",
      "(756, 40)\n",
      "(529, 40)\n",
      "(344, 40)\n",
      "(622, 40)\n",
      "(410, 40)\n",
      "(1102, 40)\n",
      "(565, 40)\n",
      "(646, 40)\n",
      "(732, 40)\n",
      "(623, 40)\n",
      "(704, 40)\n",
      "(461, 40)\n",
      "(643, 40)\n",
      "(619, 40)\n",
      "(585, 40)\n",
      "(895, 40)\n",
      "(1055, 40)\n",
      "(533, 40)\n",
      "(503, 40)\n",
      "(219, 40)\n",
      "(1093, 40)\n",
      "(674, 40)\n",
      "(1187, 40)\n",
      "(554, 40)\n",
      "(532, 40)\n",
      "(183, 40)\n",
      "(259, 40)\n",
      "(935, 40)\n",
      "(813, 40)\n",
      "(958, 40)\n",
      "(244, 40)\n",
      "(803, 40)\n",
      "(379, 40)\n",
      "(660, 40)\n",
      "(644, 40)\n",
      "(641, 40)\n",
      "(920, 40)\n",
      "(300, 40)\n",
      "(637, 40)\n",
      "(366, 40)\n",
      "(915, 40)\n",
      "(957, 40)\n",
      "(786, 40)\n",
      "(681, 40)\n",
      "(1284, 40)\n",
      "(1043, 40)\n",
      "(579, 40)\n",
      "(954, 40)\n",
      "(242, 40)\n",
      "(990, 40)\n",
      "(732, 40)\n",
      "(782, 40)\n",
      "(452, 40)\n",
      "(633, 40)\n",
      "(595, 40)\n",
      "(1196, 40)\n",
      "(571, 40)\n",
      "(449, 40)\n",
      "(475, 40)\n",
      "(545, 40)\n",
      "(628, 40)\n",
      "(454, 40)\n",
      "(757, 40)\n",
      "(392, 40)\n",
      "(845, 40)\n",
      "(773, 40)\n",
      "(815, 40)\n",
      "(717, 40)\n",
      "(1045, 40)\n",
      "(771, 40)\n",
      "(778, 40)\n",
      "(454, 40)\n",
      "(501, 40)\n",
      "(842, 40)\n",
      "(558, 40)\n",
      "(476, 40)\n",
      "(302, 40)\n",
      "(789, 40)\n",
      "(547, 40)\n",
      "(686, 40)\n",
      "(535, 40)\n",
      "(717, 40)\n",
      "(391, 40)\n",
      "(871, 40)\n",
      "(1165, 40)\n",
      "(1142, 40)\n",
      "(1185, 40)\n",
      "(617, 40)\n",
      "(737, 40)\n",
      "(545, 40)\n",
      "(1340, 40)\n",
      "(1021, 40)\n",
      "(643, 40)\n",
      "(965, 40)\n",
      "(993, 40)\n",
      "(1023, 40)\n",
      "(868, 40)\n",
      "(773, 40)\n",
      "(357, 40)\n",
      "(462, 40)\n",
      "(999, 40)\n",
      "(529, 40)\n",
      "(627, 40)\n",
      "(578, 40)\n",
      "(900, 40)\n",
      "(719, 40)\n",
      "(529, 40)\n",
      "(459, 40)\n",
      "(751, 40)\n",
      "(1142, 40)\n",
      "(416, 40)\n",
      "(392, 40)\n",
      "(347, 40)\n",
      "(479, 40)\n",
      "(1046, 40)\n",
      "(193, 40)\n",
      "(646, 40)\n",
      "(829, 40)\n",
      "(363, 40)\n",
      "(957, 40)\n",
      "(313, 40)\n",
      "(524, 40)\n",
      "(1214, 40)\n",
      "(795, 40)\n",
      "(392, 40)\n",
      "(982, 40)\n",
      "(1114, 40)\n",
      "(1302, 40)\n",
      "(667, 40)\n",
      "(980, 40)\n",
      "(843, 40)\n",
      "(1033, 40)\n",
      "(724, 40)\n",
      "(800, 40)\n",
      "(655, 40)\n",
      "(428, 40)\n",
      "(1085, 40)\n",
      "(786, 40)\n",
      "(698, 40)\n",
      "(1003, 40)\n",
      "(693, 40)\n",
      "(416, 40)\n",
      "(804, 40)\n",
      "(1252, 40)\n",
      "(898, 40)\n",
      "(436, 40)\n",
      "(528, 40)\n",
      "(806, 40)\n",
      "(418, 40)\n",
      "(1292, 40)\n",
      "(513, 40)\n",
      "(997, 40)\n",
      "(491, 40)\n",
      "(564, 40)\n",
      "(801, 40)\n",
      "(764, 40)\n",
      "(340, 40)\n",
      "(488, 40)\n",
      "(485, 40)\n",
      "(931, 40)\n",
      "(552, 40)\n",
      "(600, 40)\n",
      "(1309, 40)\n",
      "(1018, 40)\n",
      "(1477, 40)\n",
      "(579, 40)\n",
      "(497, 40)\n",
      "(556, 40)\n",
      "(391, 40)\n",
      "(865, 40)\n",
      "(1063, 40)\n",
      "(878, 40)\n",
      "(749, 40)\n",
      "(897, 40)\n",
      "(1049, 40)\n",
      "(540, 40)\n",
      "(500, 40)\n",
      "(797, 40)\n",
      "(467, 40)\n",
      "(806, 40)\n",
      "(792, 40)\n",
      "(1112, 40)\n",
      "(770, 40)\n",
      "(277, 40)\n",
      "(332, 40)\n",
      "(1153, 40)\n",
      "(938, 40)\n",
      "(1141, 40)\n",
      "(923, 40)\n",
      "(730, 40)\n",
      "(543, 40)\n",
      "(935, 40)\n",
      "(851, 40)\n",
      "(436, 40)\n",
      "(619, 40)\n",
      "(983, 40)\n",
      "(985, 40)\n",
      "(668, 40)\n",
      "(1251, 40)\n",
      "(600, 40)\n",
      "(740, 40)\n",
      "(609, 40)\n",
      "(285, 40)\n",
      "(817, 40)\n",
      "(723, 40)\n",
      "(460, 40)\n",
      "(373, 40)\n",
      "(273, 40)\n",
      "(1107, 40)\n",
      "(697, 40)\n",
      "(971, 40)\n",
      "(509, 40)\n",
      "(415, 40)\n",
      "(695, 40)\n",
      "(640, 40)\n",
      "(922, 40)\n",
      "(527, 40)\n",
      "(443, 40)\n",
      "(403, 40)\n",
      "(355, 40)\n",
      "(652, 40)\n",
      "(788, 40)\n",
      "(624, 40)\n",
      "(972, 40)\n",
      "(758, 40)\n",
      "(490, 40)\n",
      "(670, 40)\n",
      "(286, 40)\n",
      "(462, 40)\n",
      "(716, 40)\n",
      "(1007, 40)\n",
      "(766, 40)\n",
      "(989, 40)\n",
      "(212, 40)\n",
      "(1141, 40)\n",
      "(489, 40)\n",
      "(909, 40)\n",
      "(588, 40)\n",
      "(667, 40)\n",
      "(666, 40)\n",
      "(653, 40)\n",
      "(1425, 40)\n",
      "(546, 40)\n",
      "(1002, 40)\n",
      "(666, 40)\n",
      "(881, 40)\n",
      "(259, 40)\n",
      "(890, 40)\n",
      "(841, 40)\n",
      "(435, 40)\n",
      "(686, 40)\n",
      "(567, 40)\n",
      "(909, 40)\n",
      "(1205, 40)\n",
      "(1061, 40)\n",
      "(514, 40)\n",
      "(499, 40)\n",
      "(473, 40)\n",
      "(796, 40)\n",
      "(392, 40)\n",
      "(766, 40)\n",
      "(689, 40)\n",
      "(696, 40)\n",
      "(716, 40)\n",
      "(799, 40)\n",
      "(909, 40)\n",
      "(519, 40)\n",
      "(528, 40)\n",
      "(500, 40)\n",
      "(488, 40)\n",
      "(1268, 40)\n",
      "(874, 40)\n",
      "(587, 40)\n",
      "(407, 40)\n",
      "(446, 40)\n",
      "(944, 40)\n",
      "(1063, 40)\n",
      "(567, 40)\n",
      "(699, 40)\n",
      "(531, 40)\n",
      "(1039, 40)\n",
      "(542, 40)\n",
      "(809, 40)\n",
      "(881, 40)\n",
      "(742, 40)\n",
      "(736, 40)\n",
      "(696, 40)\n",
      "(729, 40)\n",
      "(940, 40)\n",
      "(387, 40)\n",
      "(785, 40)\n",
      "(597, 40)\n",
      "(857, 40)\n",
      "(1022, 40)\n",
      "(1260, 40)\n",
      "(1089, 40)\n",
      "(1104, 40)\n",
      "(778, 40)\n",
      "(1005, 40)\n",
      "(1418, 40)\n",
      "(802, 40)\n",
      "(1219, 40)\n",
      "(672, 40)\n",
      "(950, 40)\n",
      "(359, 40)\n",
      "(1046, 40)\n",
      "(345, 40)\n",
      "(592, 40)\n",
      "(652, 40)\n",
      "(977, 40)\n",
      "(683, 40)\n",
      "(626, 40)\n",
      "(411, 40)\n",
      "(340, 40)\n",
      "(770, 40)\n",
      "(1596, 40)\n",
      "(697, 40)\n",
      "(788, 40)\n",
      "(525, 40)\n",
      "(654, 40)\n",
      "(760, 40)\n",
      "(557, 40)\n",
      "(343, 40)\n",
      "(615, 40)\n",
      "(511, 40)\n",
      "(797, 40)\n",
      "(553, 40)\n",
      "(1004, 40)\n",
      "(561, 40)\n",
      "(551, 40)\n",
      "(690, 40)\n",
      "(1029, 40)\n",
      "(605, 40)\n",
      "(752, 40)\n",
      "(586, 40)\n",
      "(361, 40)\n",
      "(1020, 40)\n",
      "(290, 40)\n",
      "(638, 40)\n",
      "(283, 40)\n",
      "(608, 40)\n",
      "(901, 40)\n",
      "(375, 40)\n",
      "(963, 40)\n",
      "(755, 40)\n",
      "(1017, 40)\n",
      "(642, 40)\n",
      "(588, 40)\n",
      "(782, 40)\n",
      "(700, 40)\n",
      "(697, 40)\n",
      "(737, 40)\n",
      "(394, 40)\n",
      "(899, 40)\n",
      "(852, 40)\n",
      "(758, 40)\n",
      "(816, 40)\n",
      "(367, 40)\n",
      "(534, 40)\n",
      "(1316, 40)\n",
      "(611, 40)\n",
      "(795, 40)\n",
      "(877, 40)\n",
      "(589, 40)\n",
      "(1034, 40)\n",
      "(707, 40)\n",
      "(559, 40)\n",
      "(1481, 40)\n",
      "(829, 40)\n",
      "(988, 40)\n",
      "(634, 40)\n",
      "(1114, 40)\n",
      "(530, 40)\n",
      "(749, 40)\n",
      "(1417, 40)\n",
      "(452, 40)\n",
      "(897, 40)\n",
      "(734, 40)\n",
      "(479, 40)\n",
      "(703, 40)\n",
      "(626, 40)\n",
      "(884, 40)\n",
      "(986, 40)\n",
      "(680, 40)\n",
      "(940, 40)\n",
      "(548, 40)\n",
      "(1049, 40)\n",
      "(425, 40)\n",
      "(1600, 40)\n",
      "(1111, 40)\n",
      "(346, 40)\n",
      "(650, 40)\n",
      "(624, 40)\n",
      "(987, 40)\n",
      "(708, 40)\n",
      "(266, 40)\n",
      "(359, 40)\n",
      "(669, 40)\n",
      "(560, 40)\n",
      "(835, 40)\n",
      "(767, 40)\n",
      "(832, 40)\n",
      "(374, 40)\n",
      "(1138, 40)\n",
      "(983, 40)\n",
      "(819, 40)\n",
      "(1180, 40)\n",
      "(658, 40)\n",
      "(487, 40)\n",
      "(298, 40)\n",
      "(350, 40)\n",
      "(639, 40)\n",
      "(796, 40)\n",
      "(875, 40)\n",
      "(602, 40)\n",
      "(930, 40)\n",
      "(593, 40)\n",
      "(944, 40)\n",
      "(855, 40)\n",
      "(1123, 40)\n",
      "(874, 40)\n",
      "(986, 40)\n",
      "(974, 40)\n",
      "(426, 40)\n",
      "(494, 40)\n",
      "(529, 40)\n",
      "(677, 40)\n",
      "(900, 40)\n",
      "(1233, 40)\n",
      "(533, 40)\n",
      "(390, 40)\n",
      "(895, 40)\n",
      "(712, 40)\n",
      "(944, 40)\n",
      "(328, 40)\n",
      "(909, 40)\n",
      "(736, 40)\n",
      "(603, 40)\n",
      "(369, 40)\n",
      "(430, 40)\n",
      "(659, 40)\n",
      "(536, 40)\n",
      "(1045, 40)\n",
      "(663, 40)\n",
      "(906, 40)\n",
      "(497, 40)\n",
      "(1151, 40)\n",
      "(627, 40)\n",
      "(890, 40)\n",
      "(660, 40)\n",
      "(630, 40)\n",
      "(233, 40)\n",
      "(782, 40)\n",
      "(917, 40)\n",
      "(830, 40)\n",
      "(688, 40)\n",
      "(320, 40)\n",
      "(923, 40)\n",
      "(1159, 40)\n",
      "(889, 40)\n",
      "(641, 40)\n",
      "(1061, 40)\n",
      "(502, 40)\n"
     ]
    }
   ],
   "source": [
    "for data in test_data:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Levenshtein as L\n",
    "L.distance(\"aaaanfavaffd\", \"andfavbaffd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
